{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN\n",
    "\n",
    "# 1- Backward Propagation\n",
    "\n",
    "\n",
    "Conv -> Relu -> MaxPool -> Conv -> Relu -> MaxPool -> FC1 -> FC2 -> softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d ():\n",
    "    def __init__ (self, A, n_Cnext, hyperparameters):\n",
    "        # (样本数, 长度, 宽度, RGB数量(通道数量))\n",
    "        self.A = A\n",
    "        (m, n_H, n_W, n_C) = A.shape\n",
    "        self.m = m\n",
    "        self.n_H = n_H\n",
    "        self.n_W = n_W\n",
    "        self.n_C = n_C\n",
    "        # 输出通道数量(depth: 立方体的深度)\n",
    "        self.n_Cnext = n_Cnext\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.hyperparams = hyperparameters\n",
    "        f = hyperparameters['filter']\n",
    "        p = hyperparameters['padding']\n",
    "        s = hyperparameters['stride']\n",
    "        self.f, self.p, self.s = f, p, s\n",
    "        \n",
    "        # W, b\n",
    "        self.W = np.random.rand(f, f, n_C, n_Cnext)\n",
    "        self.b = np.random.rand(1, 1, 1, n_Cnext)\n",
    "        \n",
    "        # derivatives\n",
    "        self.dJ_dW = np.zeros(shape = self.W.shape)\n",
    "        self.dJ_db = np.zeros(shape = self.b.shape)\n",
    "        \n",
    "        # if add padding\n",
    "        pad_width = ((0, 0), (p, p), (p, p), (0, 0))\n",
    "        self.A_pad = np.pad(A, pad_width, 'constant', constant_values = 0)\n",
    "        \n",
    "        # Z_OUTPUT\n",
    "        self.n_H_next = int((n_H - f + 2 * p) / s) + 1\n",
    "        self.n_W_next = int((n_W - f + 2 * p) / s) + 1\n",
    "        self.Z = np.ones(shape = (m, self.n_H_next, self.n_W_next, n_Cnext))\n",
    "        \n",
    "        print('Weights/Filters:', self.W.shape)\n",
    "        print('bias:', self.b.shape)\n",
    "        print('derivatives W, b:', self.dJ_dW.shape, self.dJ_db.shape)\n",
    "        print('A_pad:', self.A_pad.shape)\n",
    "        print('Z_OUTPUT: ', self.Z.shape)\n",
    "        \n",
    "    def printW_b (self):\n",
    "        return (self.W, self.b)\n",
    "\n",
    "    def _Conv (self):\n",
    "        # 1. m个样本, 取一张照片\n",
    "        for _m in range(self.m):\n",
    "            A_m = self.A_pad[_m] # n_H, n_W, n_C\n",
    "            # 2. 一张照片的高\n",
    "            for _h in range(self.n_H_next):\n",
    "                # 3. 一张照片的宽\n",
    "                for _w in range(self.n_W_next):\n",
    "                    # 4. 第_c个filter/weights (filter用来提取该图像的信息, filter有横的竖的, 各个方向对图像进行边缘提取)\n",
    "                    for _c in range(self.n_Cnext):\n",
    "                        # 5. 图像根据filter尺寸, 分块儿\n",
    "                        # 按照FC逻辑来说, 选取要和weights进行匹配的neurons\n",
    "                        s, f = self.s, self.f # stride, filter\n",
    "                        w_start = _w * s\n",
    "                        w_end = _w * s + f\n",
    "                        h_start = _h * s\n",
    "                        h_end = _h * s + f\n",
    "                        \n",
    "                        # 图像块儿: 图像高宽固定, 深度保持RGB\n",
    "                        A_m_slice = A_m[h_start: h_end, w_start: w_end, :]\n",
    "                        \n",
    "                        # 6. 图像块儿 和 weights 对应位置相乘 + b\n",
    "                        Z_slice = A_m_slice * self.W[:, :, :, _c] + self.b[:, :, :, _c]\n",
    "                        \n",
    "                        # 7. 提取边界是个叠加的值\n",
    "                        Z_slice_sum = np.sum(Z_slice)\n",
    "                        \n",
    "                        # 8. 放到新的输出里面\n",
    "                        self.Z[_m, _h, _w, _c] = Z_slice_sum\n",
    "        \n",
    "        cache = (A, self.A, self.W, self.b, self.hyperparams)\n",
    "        return self.Z, cache\n",
    "    \n",
    "    def _Relu (self, Z):\n",
    "        self.Z_relu = np.maximum(0, Z)\n",
    "        return self.Z_relu\n",
    "          \n",
    "     \n",
    "    def _Max_Pooling (self, A, f = 2, s = 2):\n",
    "        self.pool_s = s\n",
    "        self.pool_f = f\n",
    "        \n",
    "        (m, n_H, n_W, n_C) = A.shape\n",
    "        n_W_next = int((n_W - f) / 2 )  + 1\n",
    "        n_H_next = int((n_H - f) / 2 )  + 1\n",
    "        \n",
    "        self.A_maxpool = np.zeros(shape = (m, n_H_next, n_W_next, n_C))\n",
    "        \n",
    "        # 1. 处理一张图像\n",
    "        for _m in range(m):\n",
    "            A_m = A[_m]\n",
    "            # 2. 高\n",
    "            for _h in range(n_H_next):\n",
    "                # 3. 宽\n",
    "                for _w in range(n_W_next):\n",
    "                    # 4. 通道 channel\n",
    "                    for _c in range(n_C):\n",
    "                        w_start = _w * s\n",
    "                        w_end = _w * s + f\n",
    "                        h_start = _h * s\n",
    "                        h_end = _h * s + f\n",
    "                        \n",
    "                        # 某个图像块儿\n",
    "                        A_m_slice = A_m[h_start: h_end, w_start: w_end, _c]\n",
    "                        \n",
    "                        # 放到新的输出里\n",
    "                        self.A_maxpool[_m, _h, _w, _c] = np.max(A_m_slice)\n",
    "                        \n",
    "        return self.A_maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu_derivative (A):\n",
    "    return 1. * (A > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPool_derivative (dJ_dA_maxpool, A_relu, f = 2, s = 2, mode = 'MAX'):\n",
    "    # dJ_dA_maxpool 导数\n",
    "    # A_prev 前一个activiation的值\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_relu.shape\n",
    "    (m, n_H, n_W, n_C) = dJ_dA_maxpool.shape\n",
    "    \n",
    "    dJ_dA_relu = np.zeros(shape = (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    for _m in range(m):\n",
    "        A_relu_m = A_relu[_m]\n",
    "        for _h in range(n_H):\n",
    "            for _w in range(n_W):\n",
    "                for _c in range(n_C):\n",
    "                    h_start = _h * s\n",
    "                    h_end = _h * s + f\n",
    "                    w_start = _w * s\n",
    "                    w_end = _w * s + f\n",
    "                    \n",
    "                    A_relu_m_slice = A_relu_m[h_start: h_end, w_start: w_end, _c]\n",
    "                    \n",
    "                    if mode == 'MAX':\n",
    "                        # 找一块里面的最大值, 并得知其index. 简单方法是和最大值匹配\n",
    "                        \"\"\"\n",
    "                        [[False False]\n",
    "                         [False  True]]\n",
    "                        \"\"\"\n",
    "                        mask = A_relu_m_slice == np.max(A_relu_m_slice) # 返回True和其他False\n",
    "                        # mask 是告诉你那个位置是需要填上最大数据 (因为是maxpool)\n",
    "                        dJ_dA_relu_slice =  mask * A_relu_m[_h, _w, _c]\n",
    "                        dJ_dA_relu[_m, h_start: h_end, w_start: w_end, _c] = dJ_dA_relu_slice\n",
    "                        \n",
    "                    if mode == 'AVERAGE':\n",
    "                        average = A_relu_m[_h, _w, _c]\n",
    "                        dJ_dA_relu[_m, h_start: h_end, w_start: w_end, _c] = np.ones(shape = (f, f)) * average\n",
    "                        \n",
    "    return dJ_dA_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_derivative (dJ_dZ, A_prev, W, b, hyperparameters):\n",
    "    f = hyperparameters['filter']\n",
    "    p = hyperparameters['padding']\n",
    "    s = hyperparameters['stride']\n",
    "    \n",
    "    \"\"\"\n",
    "    print(dJ_dZ.shape)\n",
    "    print(A_prev.shape)\n",
    "    print(W.shape)\n",
    "    print(b.shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (m, n_H, n_W, n_C) = dJ_dZ.shape\n",
    "    \n",
    "    dJ_dW = np.ones(shape = W.shape)\n",
    "    dJ_db = np.ones(shape = b.shape)\n",
    "    dJ_dA = np.ones(shape = A_prev.shape)\n",
    "    \n",
    "    pad_width = ((0, 0), (p, p), (p, p), (0, 0))\n",
    "    A_prev_pad = np.pad(A_prev, pad_width, 'constant', constant_values = 0)\n",
    "    dJ_dA_pad = np.pad(dJ_dA, pad_width, 'constant', constant_values = 0)\n",
    "    \n",
    "    for _m in range(m):\n",
    "        A_prev_pad_m = A_prev_pad[-m]\n",
    "        dJ_dA_pad_m = A_prev_pad[-m]\n",
    "        \n",
    "        for _h in range(n_H):\n",
    "            for _w in range(n_W):\n",
    "                for _c in range(n_C):\n",
    "                    dJ_dZ_slice = dJ_dZ[_m, _h, _w, _c]\n",
    "                    # 一层的所有和\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights/Filters: (2, 2, 3, 8)\n",
      "bias: (1, 1, 1, 8)\n",
      "derivatives W, b: (2, 2, 3, 8) (1, 1, 1, 8)\n",
      "A_pad: (10, 6, 6, 3)\n",
      "Z_OUTPUT:  (10, 5, 5, 8)\n",
      "(10, 5, 5, 8)\n",
      "(10, 5, 5, 8)\n",
      "(10, 2, 2, 8)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A = np.random.rand(10, 4, 4, 3)\n",
    "\n",
    "n_Cnext = 8\n",
    "hyperparameters = {\n",
    "    'filter': 2,\n",
    "    'stride': 1,\n",
    "    'padding': 1\n",
    "}\n",
    "\n",
    "# CONV LAYER\n",
    "CONV_LAYER = Conv2d(A, n_Cnext, hyperparameters)\n",
    "Z, cache = CONV_LAYER._Conv()\n",
    "print(Z.shape)\n",
    "\n",
    "# RELU\n",
    "A_relu = CONV_LAYER._Relu(Z)\n",
    "print(A_relu.shape)\n",
    "\n",
    "# POOL LAYER\n",
    "A_maxpool = CONV_LAYER._Max_Pooling(A_relu)\n",
    "print(A_maxpool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟 dJ_dA_maxpool\n",
    "dJ_dA_maxpool = np.random.randn(10, 3, 3, 8)\n",
    "\n",
    "# dJ_dA_maxpool => dJ_dA_relu\n",
    "dJ_dA_relu = MaxPool_derivative(dJ_dA_maxpool, A_relu, 2, 2, 'MAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dJ_dA_relu => dJ_dZ\n",
    "dJ_dZ = Relu_derivative(dJ_dA_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dJ_dZ => dJ_dA_prev, dW, db\n",
    "(W, b) = CONV_LAYER.printW_b()\n",
    "Conv_derivative (dJ_dZ, A, W, b, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
