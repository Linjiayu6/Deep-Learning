
# Neural Networks and Deep Learning

***

### Week2: Logistic Regression
**Practice:**
1. [2.13] Vectorizing Logistic Regression
2. [2.15] Broadcasting in Python.ipynb
3. [2.16] python _ numpy.ipynb

**Assignment:**
**1. 逻辑回归练习 (非课程)**
[W2-self] Logistic Regression demo.ipynb

**2. 逻辑回归**
[W2] Logistic Regression with a Neural Network mindset.ipynb
```
Tags:
logistic回归、损失函数、梯度下降、计算向量化、代价函数等

Layers:
- no hidden layer
- the output layer with one output

Activation Function:
- sigmoid
```
[R: Logistic Regression with a Neural Network mindset](https://github.com/enggen/Deep-Learning-Coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb)

***

### Week3: Shallow neural networks
**Assignment:**

**1. 浅层神经网络实现平面数据分类**
[W3] Planar data classification with one hidden layer.ipynb

```
Tags: 神经网络、激活函数、梯度下降法、反向传播、随机初始化

Layers:
- one hidden layer with m neurons
- the output layer with one output

Activation Function:
- tanh
- sigmoid(last layer)
```
[R: Planar data classification with one hidden layer](https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Planar%20data%20classification%20with%20one%20hidden%20layer.ipynb)

***

# Week4: Deep Neural Network

**Assignment:**
**1. 构建深层神经网络**
[W4] Building your Deep Neural Network_Step by Step.ipynb

```
Tags: 

Layers:

Activation Function:
```

[R: Building your Deep Neural Network: Step by Step](https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step.ipynb)


**2. 图像分类应用**

```
Tags: 

Layers:

Activation Function:
```

[R: Deep Neural Network for Image Classification: Application](https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Deep%20Neural%20Network%20-%20Application.ipynb)
