
# Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization

```
Week 1 - Initialization
Week 1 - Regularization
Week 1 - Gradient Checking
Week 2 - Optimization Methods
Week 3 - TensorFlow Tutorial
```

***
### Week 1 - Initialization

**Assignment:**
- W1__Initialization.ipynb

```python
# weights & bias 参数初始化的三种创建对NN影响

1. Zero Initialization
2. Random Initialization (不能选用过大的随机数, 会导致 "梯度爆炸或梯度消失")
3. He Initialization (增加缩放因子)
```

[R: Initialization](https://github.com/Kulbear/deep-learning-coursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Initialization.ipynb)

```python
# TODO

# 疑问:
1. 为什么weights 随机数过大会导致[梯度爆炸或梯度消失]?

2. 为什么He Initialization 增加缩放因子会解决问题? 解决什么问题?

```

***
